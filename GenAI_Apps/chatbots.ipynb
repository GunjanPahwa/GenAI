{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acda8a88",
   "metadata": {},
   "source": [
    "##### Building a Chatbot\n",
    "\n",
    "This chatbot will only use the language model to have a conversation, There are several other related concepts that we will work on in future:\n",
    "1. Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "2. Agents: Build a Chatbot that can take actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b5ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee7fe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"llama-3.3-70b-versatile\",groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da3ad5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x000001F3EEED3FD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F3EEF04070>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84a77772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Gunjan! Nice to meet you. It's great that you're looking for an SDE-AI (Software Development Engineer - Artificial Intelligence) role. That's a fascinating field, and I'm sure you must have a strong background in computer science, math, and AI/ML concepts.\\n\\nTo better understand your requirements, could you please tell me a bit more about your background, skills, and what you're looking for in an SDE-AI role? For example:\\n\\n* What type of AI/ML technologies are you interested in working with (e.g., computer vision, NLP, deep learning)?\\n* Do you have any specific industry or domain in mind (e.g., healthcare, finance, autonomous vehicles)?\\n* What are your preferred programming languages and tools?\\n* Are you looking for a role in a specific location or are you open to remote work?\\n* Do you have any specific experience or qualifications that you think would be relevant to an SDE-AI role?\\n\\nFeel free to share as much or as little information as you'd like, and I'll do my best to help you explore SDE-AI opportunities that fit your interests and skills!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 236, 'prompt_tokens': 53, 'total_tokens': 289, 'completion_time': 0.678792999, 'completion_tokens_details': None, 'prompt_time': 0.004728011, 'prompt_tokens_details': None, 'queue_time': 0.053721979, 'total_time': 0.68352101}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_68f543a7cc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c0416-4071-7230-ad5c-efd2c2353f86-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 53, 'output_tokens': 236, 'total_tokens': 289})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Gunjan and I am looking for an SDE-AI role\")])\n",
    "#This will give me an AIMessage which is basically a response from my LLM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1301c12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Gunjan, and you're looking for an SDE-AI (Software Development Engineer - Artificial Intelligence) role.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 311, 'total_tokens': 338, 'completion_time': 0.032647364, 'completion_tokens_details': None, 'prompt_time': 0.01991398, 'prompt_tokens_details': None, 'queue_time': 0.16166055, 'total_time': 0.052561344}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3272ea2d91', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c0419-c15d-7c13-bf38-01975b017fe4-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 311, 'output_tokens': 27, 'total_tokens': 338})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, My name is Gunjan and I am looking for an SDE-AI role\"),\n",
    "    AIMessage(content=\"Hello Gunjan! Nice to meet you. It's great that you're looking for an SDE-AI (Software Development Engineer - Artificial Intelligence) role. That's a fascinating field, and I'm sure you must have a strong background in computer science, math, and AI/ML concepts.\\n\\nTo better understand your requirements, could you please tell me a bit more about your background, skills, and what you're looking for in an SDE-AI role? For example:\\n\\n* What type of AI/ML technologies are you interested in working with (e.g., computer vision, NLP, deep learning)?\\n* Do you have any specific industry or domain in mind (e.g., healthcare, finance, autonomous vehicles)?\\n* What are your preferred programming languages and tools?\\n* Are you looking for a role in a specific location or are you open to remote work?\\n* Do you have any specific experience or qualifications that you think would be relevant to an SDE-AI role?\\n\\nFeel free to share as much or as little information as you'd like, and I'll do my best to help you explore SDE-AI opportunities that fit your interests and skills!\"),\n",
    "    HumanMessage(content=\"Hi, What;s my name and what am I looking for?\")\n",
    "]) #Here i am hardcoding the AIMessage, the message i got from the previous cell\n",
    "#I am then asking the AI whether it can remember the message i gave it before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b64df6",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a6994a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "#Now as different different users and simultaneously interacting with the chatbot we need to make sure that one session is completely different from the other session\n",
    "#We will create a function for that with the parameter as session id which is a string\n",
    "#The resturn type of this function would be BaseChatMessageHistory--->whatever chat history is created it is imported from this library\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory: #this session id will be used to distinguish between sessions\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory() #this is an object of chat message history\n",
    "        #we are storing the session id in the store dictionary\n",
    "        #With respect to the session id value i am initializing a chat message history\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n",
    "#this ensures that we can interact with our LLM model based on our chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2505ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}} #here i am hardcoding the session id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eba829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Gunjan and I am looking for an SDE-AI role\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7529295b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Gunjan, nice to meet you! I'd be happy to help you with your job search for an SDE-AI (Software Development Engineer - Artificial Intelligence) role.\\n\\nTo get started, can you tell me a bit about your background and experience? For example:\\n\\n* What type of degree do you have (e.g. Bachelor's, Master's, Ph.D.) and in what field (e.g. Computer Science, Mathematics, Engineering)?\\n* Do you have any prior experience working with AI or ML technologies (e.g. internships, projects, research experience)?\\n* What programming languages are you proficient in (e.g. Python, Java, C++).\\n* Are you familiar with any deep learning frameworks (e.g. TensorFlow, PyTorch, Keras)?\\n\\nAlso, what specific areas of AI are you interested in (e.g. computer vision, natural language processing, robotics)?\\n\\nLastly, what are your expectations from an SDE-AI role (e.g. job responsibilities, company culture, growth opportunities)? \\n\\nThis will help me understand your profile better and provide more tailored guidance and support.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d1ecd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Gunjan.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 544, 'total_tokens': 551, 'completion_time': 0.006888205, 'completion_tokens_details': None, 'prompt_time': 0.027596556, 'prompt_tokens_details': None, 'queue_time': 0.052730521, 'total_time': 0.034484761}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c0429-846d-7df3-89b6-5a0bb99e5de3-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 544, 'output_tokens': 7, 'total_tokens': 551})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3d9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. I'm a large language model, I don't have the ability to recall personal information about individuals, and our conversation just started, so I haven't been given any information about you. If you'd like to share your name, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the config--->session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef93e39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Gina! It's lovely to have you here. Is there something I can help you with or would you like to chat? I'm all ears!\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name if Gina\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83e50bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I remember! Your name is Gina. We just introduced ourselves a moment ago.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f586019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb2e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb047b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ab077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c2d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27c3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff0fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb06c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea35e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319b226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400d032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
