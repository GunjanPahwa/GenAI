{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acda8a88",
   "metadata": {},
   "source": [
    "##### Building a Chatbot\n",
    "\n",
    "This chatbot will only use the language model to have a conversation, There are several other related concepts that we will work on in future:\n",
    "1. Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "2. Agents: Build a Chatbot that can take actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b5ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee7fe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"llama-3.3-70b-versatile\",groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3ad5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x0000024C59120340>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000024C590576D0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a77772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Gunjan! I'd be happy to help you with your job search for an SDE-AI (Software Development Engineer - Artificial Intelligence) role.\\n\\nTo get started, could you please tell me a bit more about your background and what you're looking for in an SDE-AI role? For example:\\n\\n* What's your current level of experience (e.g., fresher, 2-5 years, 5+ years)?\\n* What type of AI/ML technologies are you interested in working with (e.g., computer vision, NLP, deep learning)?\\n* Are you looking for a specific industry or domain (e.g., healthcare, finance, autonomous vehicles)?\\n* Do you have any preferred locations for the role (e.g., specific cities, remote work)?\\n* What are your salary expectations?\\n\\nFeel free to share any other relevant details about your qualifications, skills, and interests. I'll do my best to provide you with helpful guidance and resources for your job search!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 204, 'prompt_tokens': 53, 'total_tokens': 257, 'completion_time': 0.556454087, 'completion_tokens_details': None, 'prompt_time': 0.001954643, 'prompt_tokens_details': None, 'queue_time': 0.057418177, 'total_time': 0.55840873}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c18aa-eaad-7ac0-8b1c-37b1bc5cf979-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 53, 'output_tokens': 204, 'total_tokens': 257})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Gunjan and I am looking for an SDE-AI role\")])\n",
    "#This will give me an AIMessage which is basically a response from my LLM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1301c12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Gunjan, and you are looking for an SDE-AI (Software Development Engineer - Artificial Intelligence) role.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 311, 'total_tokens': 338, 'completion_time': 0.032351481, 'completion_tokens_details': None, 'prompt_time': 0.015378982, 'prompt_tokens_details': None, 'queue_time': 0.056355737, 'total_time': 0.047730463}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_68f543a7cc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c18aa-ed99-7c81-8f75-ebed71dcc582-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 311, 'output_tokens': 27, 'total_tokens': 338})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, My name is Gunjan and I am looking for an SDE-AI role\"),\n",
    "    AIMessage(content=\"Hello Gunjan! Nice to meet you. It's great that you're looking for an SDE-AI (Software Development Engineer - Artificial Intelligence) role. That's a fascinating field, and I'm sure you must have a strong background in computer science, math, and AI/ML concepts.\\n\\nTo better understand your requirements, could you please tell me a bit more about your background, skills, and what you're looking for in an SDE-AI role? For example:\\n\\n* What type of AI/ML technologies are you interested in working with (e.g., computer vision, NLP, deep learning)?\\n* Do you have any specific industry or domain in mind (e.g., healthcare, finance, autonomous vehicles)?\\n* What are your preferred programming languages and tools?\\n* Are you looking for a role in a specific location or are you open to remote work?\\n* Do you have any specific experience or qualifications that you think would be relevant to an SDE-AI role?\\n\\nFeel free to share as much or as little information as you'd like, and I'll do my best to help you explore SDE-AI opportunities that fit your interests and skills!\"),\n",
    "    HumanMessage(content=\"Hi, What;s my name and what am I looking for?\")\n",
    "]) #Here i am hardcoding the AIMessage, the message i got from the previous cell\n",
    "#I am then asking the AI whether it can remember the message i gave it before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b64df6",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6994a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "#Now as different different users and simultaneously interacting with the chatbot we need to make sure that one session is completely different from the other session\n",
    "#We will create a function for that with the parameter as session id which is a string\n",
    "#The resturn type of this function would be BaseChatMessageHistory--->whatever chat history is created it is imported from this library\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory: #this session id will be used to distinguish between sessions\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory() #this is an object of chat message history\n",
    "        #we are storing the session id in the store dictionary\n",
    "        #With respect to the session id value i am initializing a chat message history\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n",
    "#this ensures that we can interact with our LLM model based on our chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2505ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}} #here i am hardcoding the session id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eba829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Gunjan and I am looking for an SDE-AI role\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7529295b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Gunjan, nice to meet you! Congratulations on exploring opportunities in the field of Software Development Engineering - Artificial Intelligence (SDE-AI). That's a fascinating and in-demand role.\\n\\nTo better understand your requirements and preferences, could you please share some details about your background and what you're looking for in an SDE-AI role? For example:\\n\\n* What's your current level of experience (entry-level, mid-level, senior-level)?\\n* What specific areas of AI interest you the most (e.g., machine learning, natural language processing, computer vision)?\\n* Are you looking for a role in a particular industry (e.g., healthcare, finance, tech)?\\n* Do you have any preferred locations or are you open to remote work?\\n* What are your salary expectations?\\n\\nFeel free to share as much or as little information as you'd like, and I'll do my best to help you explore SDE-AI opportunities that fit your goals and aspirations!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d1ecd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Gunjan.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 262, 'total_tokens': 269, 'completion_time': 0.006961073, 'completion_tokens_details': None, 'prompt_time': 0.013635419, 'prompt_tokens_details': None, 'queue_time': 0.057270381, 'total_time': 0.020596492}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c18aa-f164-7c31-89cc-36b2a1066456-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 262, 'output_tokens': 7, 'total_tokens': 269})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd3d9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. I'm a large language model, I don't have any information about you, including your name. I'm a text-based AI assistant, and our conversation just started, so I don't have any prior knowledge about you. If you'd like to share your name, I'd be happy to chat with you and use it in our conversation!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the config--->session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef93e39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Gina! It's nice to meet you! I'll make sure to address you by your name in our conversation. How's your day going so far? Is there something I can help you with or would you like to chat about anything in particular?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name if Gina\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e50bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I remember! Your name is Gina.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab6fe8",
   "metadata": {},
   "source": [
    "##### Prompt templates\n",
    "\n",
    "Prompt templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make it a bit more complicated. First let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a127e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful assistant. Answer all questions to the best of your ability\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ade7790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Gunjan! It's nice to meet you. Is there something I can help you with or would you like to chat? I'm here to assist you with any questions or topics you'd like to discuss. How's your day going so far?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 57, 'total_tokens': 109, 'completion_time': 0.107014351, 'completion_tokens_details': None, 'prompt_time': 0.00522166, 'prompt_tokens_details': None, 'queue_time': 0.053405547, 'total_time': 0.112236011}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c18aa-f4f0-72d3-9eac-a5954c9d9cb4-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 57, 'output_tokens': 52, 'total_tokens': 109})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Whatever human message i give needs to be given in a key value pair and the key name should be \"messages\"\n",
    "#Earlier i was not using any message placeholder so i was giving a list of messages like human message, system message, ai message\n",
    "#Here I have specified that I will use a message placeholder called as messages\n",
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi, My name is Gunjan\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dd9564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "011e669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hi my name in gunjan\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "931e9bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Gunjan, it's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 56, 'total_tokens': 83, 'completion_time': 0.054222771, 'completion_tokens_details': None, 'prompt_time': 0.002701883, 'prompt_tokens_details': None, 'queue_time': 0.053248976, 'total_time': 0.056924654}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c18aa-f5eb-7332-b65e-00a2da97b08f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 56, 'output_tokens': 27, 'total_tokens': 83})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae0b9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84eed1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते गुंजन, मैं आपकी सहायता के लिए तैयार हूँ। क्या मैं आपकी किसी प्रश्न या समस्या का समाधान कर सकता हूँ?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi, my name is Gunjan\")],\"language\":\"Hindu0\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e5b1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's wrap this more complicated chain in message history class\n",
    "#We need to specify correct key to use and save the chat history\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04435fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आपका नाम गुंजन है।'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"language\":\"Hindi\",\"messages\":[HumanMessage(content=\"Whats my name\")]},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d218f22e",
   "metadata": {},
   "source": [
    "#### Managing Conversation History\n",
    "\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of messages you are passing in.\n",
    "'trim_messages' helps to reduce how many messages we are sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23259008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=50,\n",
    "    strategy=\"last\", #start counting tokens from the last message\n",
    "    token_counter=model,\n",
    "    include_system=True, #include system message\n",
    "    allow_partial=False, #i dont want partial information\n",
    "    start_on=\"human\" #start from human conversation\n",
    "\n",
    ")\n",
    "messages=[\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm Gunjan\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem\"),\n",
    "    HumanMessage(content=\"Having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11767ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='whats 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='Having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages) #it will take 50 tokens from last message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "868cae0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You like vanilla ice cream!'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to pass trimmer in a chain\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer) #using this we can retrieve entire messages available in prompt template\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "response=chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"what ice cream do i like\")],\n",
    "    \"language\":\"English\"}\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8aa3071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked me to solve the math problem \"2+2\".'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "    \"language\":\"English\"}\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f88a2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets wrap this in the message history\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f6786ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked me to solve the math problem \"2+2\". The answer was 4.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "    \"language\":\"English\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8219980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3058455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4d39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c62ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddfcc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d1407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b05de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e58a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7f86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4a23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a6d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a83ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abbecaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfab03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b903fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe2dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9270566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18662e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ce546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978b098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7898dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c7d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1030f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7de66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa79f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc900315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61d0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f586019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb2e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb047b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ab077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c2d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27c3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff0fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb06c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea35e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319b226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400d032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
