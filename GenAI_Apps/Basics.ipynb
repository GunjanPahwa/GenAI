{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43ff2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LangSmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "783dcee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "961e9c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085db773",
   "metadata": {},
   "source": [
    "##### If i used OpenAI my code would've been\n",
    "from langchain.openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model='gpt-4o)\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e98e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True} client=<groq.resources.chat.completions.Completions object at 0x000001D7570FEF50> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001D757A12D70> model_name='llama-3.3-70b-versatile' model_kwargs={} groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f889b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and get response from LLM\n",
    "result=llm.invoke(\"What is generative AI?\")\n",
    "#using langchain api key we are storing all these results in langsmith\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03eb62ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a type of artificial intelligence that is capable of generating new, original content, such as images, videos, music, text, or even entire datasets. This is in contrast to traditional AI systems, which are typically designed to analyze and process existing data.\\n\\nGenerative AI models use complex algorithms and neural networks to learn patterns and relationships within a given dataset, and then use this knowledge to create new, synthetic data that is similar in style and structure to the original data. This can be done for a variety of purposes, such as:\\n\\n1. **Data augmentation**: generating new data to supplement existing datasets, which can help improve the performance of machine learning models.\\n2. **Content creation**: generating new images, videos, music, or text for artistic, entertainment, or marketing purposes.\\n3. **Simulation**: generating realistic simulations of real-world environments or scenarios, which can be used for training, testing, or research purposes.\\n4. **Style transfer**: transferring the style of one image or dataset to another, which can be used for artistic or creative purposes.\\n\\nSome common techniques used in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs)**: a type of neural network that consists of two models: a generator and a discriminator. The generator creates new data, while the discriminator evaluates the generated data and tells the generator whether it is realistic or not.\\n2. **Variational Autoencoders (VAEs)**: a type of neural network that learns to compress and reconstruct data, which can be used to generate new data that is similar in style and structure to the original data.\\n3. **Transformers**: a type of neural network that is particularly well-suited for natural language processing tasks, and can be used to generate text or dialogue.\\n\\nGenerative AI has many potential applications, including:\\n\\n1. **Art and design**: generating new images, videos, or music that can be used for artistic or creative purposes.\\n2. **Entertainment**: generating new content, such as videos or video games, that can be used for entertainment purposes.\\n3. **Marketing**: generating new content, such as product images or advertisements, that can be used for marketing purposes.\\n4. **Research**: generating new data or simulations that can be used to test hypotheses or train machine learning models.\\n\\nHowever, generative AI also raises important questions about authorship, ownership, and the potential for misuse, such as:\\n\\n1. **Intellectual property**: who owns the rights to generated content, and how can we ensure that it is not used for malicious purposes?\\n2. **Authenticity**: how can we determine whether generated content is real or fake, and what are the implications for trust and credibility?\\n3. **Bias and fairness**: how can we ensure that generated content is fair and unbiased, and does not perpetuate existing social or cultural biases?\\n\\nOverall, generative AI is a rapidly evolving field that has the potential to revolutionize many areas of human creativity and innovation, but also raises important questions about the responsible development and use of these technologies.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 620, 'prompt_tokens': 41, 'total_tokens': 661, 'completion_time': 1.650851128, 'completion_tokens_details': None, 'prompt_time': 0.001924731, 'prompt_tokens_details': None, 'queue_time': 0.053328639, 'total_time': 1.6527758590000001}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bef70-bf54-71e0-b1a7-af33ec9306cd-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 41, 'output_tokens': 620, 'total_tokens': 661}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f01a21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### ChatPrompt Template\n",
    "#How i want my LLM model to behave\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the question.\"), #Asking my \"system\" i.e. LLM to behave like an AI Engineer\n",
    "        (\"user\",\"{input}\") #user will give you inputs\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ace015ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"LangSmith is an AI-powered language learning platform that utilizes natural language processing (NLP) and machine learning algorithms to help users learn new languages. It was developed by a team of language learning experts, AI researchers, and software engineers.\\n\\nThe platform uses a combination of interactive lessons, conversations with AI-powered chatbots, and speech recognition technology to help users improve their language skills. LangSmith's AI engine analyzes the user's language proficiency, learning style, and goals to create personalized lessons and provide real-time feedback.\\n\\nSome of the key features of LangSmith include:\\n\\n1. **Conversational AI**: Engage in conversations with AI-powered chatbots that simulate real-life conversations, helping users improve their speaking and listening skills.\\n2. **Personalized learning**: The platform uses machine learning algorithms to create customized lessons based on the user's language level, learning style, and goals.\\n3. **Speech recognition**: LangSmith's speech recognition technology helps users improve their pronunciation by providing real-time feedback on their speech.\\n4. **Interactive lessons**: The platform offers a range of interactive lessons, including grammar exercises, vocabulary building, and reading comprehension.\\n5. **Gamification**: LangSmith incorporates gamification elements, such as rewards, badges, and leaderboards, to make language learning more engaging and fun.\\n\\nLangSmith supports multiple languages, including popular languages like English, Spanish, French, German, Chinese, and many more. The platform is available as a web application, mobile app, and can be accessed on various devices.\\n\\nOverall, LangSmith is an innovative language learning platform that leverages AI and machine learning to provide an immersive and effective language learning experience.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 331, 'prompt_tokens': 58, 'total_tokens': 389, 'completion_time': 1.122171961, 'completion_tokens_details': None, 'prompt_time': 0.005161626, 'prompt_tokens_details': None, 'queue_time': 0.059323953, 'total_time': 1.127333587}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_68f543a7cc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bef7b-9ff2-7650-8912-a3be5062ca5b-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 58, 'output_tokens': 331, 'total_tokens': 389}\n"
     ]
    }
   ],
   "source": [
    "#Now i have to use this prompt template along with my llm model, so i will go ahead and create a chain\n",
    "#the chain will tell my LLM model what it has to behave like based on the prompt\n",
    "chain=prompt|llm #this means combine this prompt along with my LLM\n",
    "#now when i give any input it will first go through the prompt and then the llm \n",
    "response=chain.invoke({\"input\":\"Can you tell me about LangSmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7beb1cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4151d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now i want some output parser to display my response\n",
    "#stroutput parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b49ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The placement process for AI Engineers typically involves several stages, which may vary depending on the company, location, and specific job requirements. Here's an overview of the common stages involved in the placement process for AI Engineers:\n",
      "\n",
      "**Stage 1: Online Application and Resume Screening**\n",
      "\n",
      "* Candidates submit their resumes and cover letters through the company's website, job portals, or recruitment agencies.\n",
      "* The hiring team reviews the applications to ensure the candidates meet the basic qualifications and requirements for the AI Engineer position.\n",
      "\n",
      "**Stage 2: Online Assessments and Coding Tests**\n",
      "\n",
      "* Candidates may be required to complete online assessments, such as:\n",
      "\t+ Coding tests (e.g., HackerRank, LeetCode, Codewars) to evaluate their programming skills in languages like Python, Java, or C++.\n",
      "\t+ Multiple-choice questions to assess their knowledge of AI and ML concepts, data structures, and algorithms.\n",
      "\t+ Data science and machine learning challenges to evaluate their problem-solving skills and ability to work with data.\n",
      "\n",
      "**Stage 3: Technical Phone or Video Interviews**\n",
      "\n",
      "* Candidates who pass the online assessments are invited for a technical phone or video interview with a member of the hiring team.\n",
      "* The interview typically lasts 30-60 minutes and covers topics such as:\n",
      "\t+ AI and ML concepts, including deep learning, natural language processing, and computer vision.\n",
      "\t+ Programming skills and experience with relevant tools and technologies.\n",
      "\t+ Problem-solving and critical thinking abilities.\n",
      "\n",
      "**Stage 4: In-Person Interviews**\n",
      "\n",
      "* Candidates who pass the technical phone or video interview are invited for an in-person interview with the hiring team.\n",
      "* The in-person interview may include:\n",
      "\t+ Technical discussions with the team to assess the candidate's communication skills, teamwork, and fit with the company culture.\n",
      "\t+ Presentations or whiteboarding exercises to evaluate the candidate's problem-solving skills and ability to think critically.\n",
      "\t+ Behavioral interviews to assess the candidate's past experiences, achievements, and career goals.\n",
      "\n",
      "**Stage 5: Project-Based Interviews or Hackathons**\n",
      "\n",
      "* Some companies may conduct project-based interviews or hackathons to evaluate the candidate's skills in a more practical setting.\n",
      "* Candidates are given a real-world problem or a dataset to work on, and they are expected to develop a solution within a set timeframe (e.g., 2-3 hours).\n",
      "* The project-based interview or hackathon assesses the candidate's ability to work under pressure, think creatively, and develop innovative solutions.\n",
      "\n",
      "**Stage 6: Final Interview with the Hiring Manager or Panel**\n",
      "\n",
      "* Candidates who pass the previous stages are invited for a final interview with the hiring manager or a panel of experts.\n",
      "* The final interview is an opportunity for the candidate to:\n",
      "\t+ Discuss their career goals, motivations, and expectations.\n",
      "\t+ Ask questions about the company, the role, and the team.\n",
      "\t+ Negotiate salary, benefits, and other employment terms.\n",
      "\n",
      "**Stage 7: Job Offer and Onboarding**\n",
      "\n",
      "* If the candidate is selected, they receive a job offer that includes details about the salary, benefits, and other employment terms.\n",
      "* The candidate must accept the offer and complete any necessary paperwork, such as background checks or reference checks.\n",
      "* The onboarding process typically includes an orientation program, training sessions, and introductions to the team and the company culture.\n",
      "\n",
      "Keep in mind that the placement process may vary depending on the company, and some stages may be skipped or combined. It's essential to research the company and the specific job requirements to prepare for the placement process.\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"Can you tell me about placement process for AI Engineer\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70daa240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035e0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351770a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10eac17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
